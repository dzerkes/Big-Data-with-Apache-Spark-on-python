{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import DateType\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Q1\").getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "path_trip = \"hdfs://master:9000/yellow_tripdata_1m.csv\"\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Q1_rdd\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "rdd = sc.textFile(path_trip)\n",
    "\n",
    "def extract_hour(x):\n",
    "    return \"{:02d}\".format(datetime.strptime(x, '%Y-%m-%d %H:%M:%S').hour)\n",
    "\n",
    "'''filter(logical condition(s)): Return a new RDD containing only the elements that satisfy a predicate.'''\n",
    "\n",
    "def filter_data(x):\n",
    "    values = x.split(\",\")\n",
    "    start_time = datetime.strptime(values[1], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(values[2], '%Y-%m-%d %H:%M:%S')\n",
    "    start_long = float(values[3])\n",
    "    start_lat = float(values[4])\n",
    "    end_long = float(values[5])\n",
    "    end_lat = float(values[6])\n",
    "    return (start_time < end_time)\\\n",
    "            and ((start_long != end_long) \\\n",
    "            and (start_lat != end_lat)) and \\\n",
    "           (start_lat >= 40) and (start_lat <= 45) \\\n",
    "            and (end_lat >= 40) and (end_lat <= 45) and \\\n",
    "           (start_long >= -80) and (start_long <= -71)\\\n",
    "            and (end_long >= -80) and (end_long <= -71)\n",
    "\n",
    "res = rdd.filter(filter_data).map(lambda x: (extract_hour(x.split(',')[1]), \\\n",
    "                (float(x.split(',')[3]), float(x.split(',')[4]),1))).\\\n",
    "                reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1], x[2]+y[2])).\\\n",
    "                sortByKey(ascending = True).\\\n",
    "                map(lambda x: (x[0],x[1][0]/x[1][2], x[1][1]/x[1][2]))\n",
    "\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "total_time = t2-t1\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for i in res.collect():\n",
    "        print(i)\n",
    "\n",
    "print(\"total time to run: \", total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Ποια είναι η μέση τιμή του γεωγραφικού μήκους και πλάτους επιβίβασης ανά ώρα έναρξης της διαδρομής;  \n",
    "  \n",
    "#### Ταξινομείστε το αποτέλεσμα με βάση την ώρα έναρξης σε αύξουσα σειρά και αγνοείστε dirty εγγραφές που προκαλούν προβληματικά αποτελέσματα (π.χ. Γεωγραφικό μήκος / πλάτος με μηδενική τιμή)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Διαδικασία:  \n",
    "  \n",
    "- κρατάμε τις τούπλες: (ώρα εκκίνησης, (γεωγραφικό μήκος, γεωγραφικό πλάτος))  \n",
    "- κάνουμε reduceByKey έτσι ώστε να αθροίσουμε τα γ.μ. και γ.π. και τις συχνότητες εμφάνισης του κάθε key (ώρα)\n",
    "- διαιρούμε τα αθροίσματα με τις συχνότητες εμφάνισης του κάθε key για να εξαχθούν οι Μ.Ο."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Συνάρτηση filter_data()  \n",
    "  \n",
    "- χωρίζει κάθε γραμμή επιστρέφοντας τούπλα  \n",
    "- σπάει τις ημερομηνίες/ώρες στη μορφή datetime.datetime (Year, Month, Day, Hour, Minute, Second)  \n",
    "- κρατάει σε float type τα γ.μ. και γ.π.  \n",
    "  \n",
    "επιστρέφει μια συνθήκη (predicate) με την οποία θα φιλτραριστεί το rdd που έχουμε"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
