{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Debt collection', 'transworld systems inc is trying to collect a debt that is not mine not owed and is inaccurate')\n",
      "\n",
      "\n",
      "('Credit reporting credit repair services or other personal consumer reports', 'i would like to request the suppression of the following items from my credit report which are the result of my falling victim to identity theft this information does not relate to transactions that i have made accounts that i have opened as the attached supporting documentation can attest as such it should be blocked from appearing on my credit report pursuant to section b of the fair credit reporting act')\n",
      "\n",
      "\n",
      "(('Debt collection', ['debt']), 0) \n",
      "\n",
      "(('Credit reporting credit repair services or other personal consumer reports', ['would', 'credit', 'report', 'information', 'made', 'accounts', 'credit', 'report', 'credit', 'reporting']), 1) \n",
      "\n",
      "('reporting', ('Credit reporting credit repair services or other personal consumer reports', 1, 1)) \n",
      "\n",
      "('told', ('Debt collection', 2, 1)) \n",
      "\n",
      "('credit', 0.6134534129199751) \n",
      "\n",
      "('account', 0.8680906666228299) \n",
      "\n",
      "('report', 1.0995128555563307) \n",
      "\n",
      "('would', 1.2809725409358188) \n",
      "\n",
      "('information', 1.3034012396333907) \n",
      "\n",
      "('even', (('Debt collection', 4, 1), 1.9778512883808954)) \n",
      "\n",
      "('even', (('Mortgage', 21, 1), 1.9778512883808954)) \n",
      "\n",
      "('even', (('Credit reporting credit repair services or other personal consumer reports', 373, 2), 1.9778512883808954)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import nltk \n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from nltk.corpus import stopwords as sw\n",
    "\n",
    "stopwords = sw.words('english') + ['xxxx' , 'xxx' ,'' , 'xx' , 'x']\n",
    "\n",
    "spark = SparkSession.builder.appName(\"tfidf\").getOrCreate()\n",
    "from pyspark.sql.functions import avg\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "def filter_data(x):\n",
    "    values = x.split(\",\")\n",
    "    if len(values) == 3:\n",
    "        date = values[0]\n",
    "        label = values[1]\n",
    "        comment = values[2]\n",
    "        if (len(comment) != 0):\n",
    "            return (date.startswith(\"201\"))  \n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def parse_data(x):\n",
    "    values = x.split(\",\")\n",
    "    label = values[1]\n",
    "    comment = re.sub('[^a-zA-Z]+', ' ', values[2]).lower().strip()\n",
    "    return label,comment\n",
    "\n",
    "\n",
    "data = sc.textFile(\"customer_complaints.csv\").filter(filter_data).map(parse_data)\n",
    "regs_number = data.count()\n",
    "\n",
    "for i in data.take(2):              \n",
    "    print(i)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "\n",
    "lexicon_size = 50\n",
    "unique_words = data.flatMap(lambda x: x[1].split(\" \")).\\\n",
    "                          filter(lambda x: x not in stopwords).\\\n",
    "                          map(lambda x : (x,1)).\\\n",
    "                          reduceByKey(lambda x,y : x+y ).\\\n",
    "                          sortBy(lambda x: x[1],ascending=False).\\\n",
    "                          map(lambda x : x[0]).\\\n",
    "                          take(lexicon_size)\n",
    "\n",
    "uwords = sc.broadcast(unique_words)\n",
    "\n",
    "#customer complaints\n",
    "cc = data.map(lambda x: (x[0],x[1].split(\" \"))).\\\n",
    "            map(lambda x : (x[0], [y for y in x[1] if y in uwords.value])).\\\n",
    "            filter(lambda x: len(x[1]) !=0).\\\n",
    "            zipWithIndex()\n",
    "            #((string_label,list_of_words),sentence_index)\n",
    "    \n",
    "for i in cc.take(2):\n",
    "    print(i ,'\\n')\n",
    "\n",
    "#Ft,d (we'll calculate the double normalized TF later)\n",
    "tf = cc.flatMap(lambda x : [((y,x[0][0],x[1]),1) for y in x[0][1]]).\\\n",
    "            reduceByKey(lambda x,y : x + y).\\\n",
    "            map(lambda x : (x[0][0],(x[0][1],x[0][2],x[1])))\n",
    "            #((word,label,sentence_index),Ft,d) before map\n",
    "            #(word,(label,sentence_index,Ft,d)) after map -> final form\n",
    "    \n",
    "for i in tf.take(2):\n",
    "    print(i,'\\n')\n",
    "\n",
    "#IDF\n",
    "idf = cc.flatMap(lambda x: [(y,1) for y in set(x[0][1])]).\\\n",
    "              reduceByKey(lambda x ,y: x+y).\\\n",
    "              sortBy(lambda x: x[1],ascending=False).\\\n",
    "              map(lambda x : (x[0],math.log(regs_number/x[1])))\n",
    "\n",
    "for i in idf.take(5):\n",
    "    print(i,\"\\n\")\n",
    "    \n",
    "##tfidf rdd\n",
    "tfidf = tf.join(idf)\n",
    "\n",
    "for i in tfidf.take(3):\n",
    "    print(i,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__final computation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mortgage', 50, [4, 5, 9, 10, 11, 14, 16, 20, 25, 26, 29, 34, 35, 36, 39, 41, 49], [1.5173549646931856, 0.7777333284253185, 0.8544062422352126, 0.7646471900037972, 0.7715629477496364, 0.7783573388778917, 0.9761484356488878, 1.050871547063804, 1.4970595167873013, 0.9930948495997832, 0.93266869202192, 1.068075278024588, 1.015104253003259, 1.008469042402106, 1.3261363149177803, 1.1275624362358958, 1.059563190204051]) \n",
      "\n",
      "('Mortgage', 50, [5, 10, 14, 16, 17, 23, 24, 25, 34, 47, 49], [0.960729405701864, 1.070506066005316, 0.9080835620242069, 1.138839841590369, 0.9749312178656413, 1.041237298125056, 1.0037106771629942, 2.2061929721076017, 1.1682073353393931, 1.272538879183559, 1.2361570552380596]) \n",
      "\n",
      "('Debt collection', 50, [3, 6, 8, 14, 23, 25, 27, 42, 46, 49], [1.1730611156700517, 0.9586568884298988, 1.0313902292260002, 0.8717602195432387, 1.1661857739000625, 1.323715783264561, 1.105093611128405, 1.088378676095442, 2.1698365566224522, 1.1867107730285371]) \n",
      "\n",
      "('Credit reporting credit repair services or other personal consumer reports', 50, [1, 2, 3, 10, 17, 18, 19, 24, 32, 34, 36, 42, 49], [0.8680906666228299, 0.6871955347227067, 0.8146257747708692, 1.4273414213404214, 0.9749312178656413, 1.3135027241393864, 1.332379828721337, 1.0037106771629942, 1.284181541560129, 1.1682073353393931, 1.1765472161357906, 1.1337277875994187, 1.2361570552380596]) \n",
      "\n",
      "('Mortgage', 50, [4, 5, 6, 10, 13, 22, 23, 24, 25, 26, 29, 30, 31, 41, 47, 49], [1.5173549646931856, 0.747233982212561, 1.3314679005970818, 0.9515609475602809, 1.1226013695800272, 1.0197132532010305, 1.1106531180000596, 0.9367966320187946, 1.470795314738401, 1.0813699473419862, 1.0155725757572018, 1.1997664113751378, 1.2150480763965898, 1.2277902083457535, 1.6967185055780785, 1.1537465848888557]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = tfidf.map(lambda x: (uwords.value.index(x[0]),x[1])).\\\n",
    "            map(lambda x: ((x[1][0][1],x[1][0][0]),(x[0],x[1][0][2],x[1][1]))).\\\n",
    "            map(lambda x: (x[0],([x[1][0]],[x[1][1]],[x[1][2]]))).\\\n",
    "            reduceByKey(lambda x,y: (x[0] + y[0],x[1] + y[1],x[2]+y[2])).\\\n",
    "            map(lambda x: (x[0],(x[1][0],[0.5 + 0.5*y/max(x[1][1]) for y in x[1][1]],x[1][2]))).\\\n",
    "            map(lambda x: (x[0][1],lexicon_size,[(x[1][0][i],x[1][1][i]*x[1][2][i]) for i in range(len(x[1][0]))])).\\\n",
    "            map(lambda x: (x[0],x[1],sorted(x[2],key=lambda y:y[0]))).\\\n",
    "            map(lambda x: (x[0],x[1],[y[0] for y in x[2]],[k[1] for k in x[2]]))\n",
    "            \n",
    "            \n",
    "\n",
    "for i in res.take(5):\n",
    "    print(i,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sparse vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mortgage', SparseVector(50, {4: 1.5174, 5: 0.7777, 9: 0.8544, 10: 0.7646, 11: 0.7716, 14: 0.7784, 16: 0.9761, 20: 1.0509, 25: 1.4971, 26: 0.9931, 29: 0.9327, 34: 1.0681, 35: 1.0151, 36: 1.0085, 39: 1.3261, 41: 1.1276, 49: 1.0596}))\n",
      "('Mortgage', SparseVector(50, {5: 0.9607, 10: 1.0705, 14: 0.9081, 16: 1.1388, 17: 0.9749, 23: 1.0412, 24: 1.0037, 25: 2.2062, 34: 1.1682, 47: 1.2725, 49: 1.2362}))\n"
     ]
    }
   ],
   "source": [
    "sv = res.map(lambda x :(x[0],SparseVector(lexicon_size,x[2],x[3])))\n",
    "for i in sv.take(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframe + stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = sv.toDF([\"label_f\",\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"label_f\",outputCol = \"label\")\n",
    "stringIndexer.setHandleInvalid(\"skip\")\n",
    "stringIndexerModel = stringIndexer.fit(cc_df)\n",
    "cc_df = stringIndexerModel.transform(cc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|             label_f|            features|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|            Mortgage|(50,[4,5,9,10,11,...|  2.0|\n",
      "|            Mortgage|(50,[5,10,14,16,1...|  2.0|\n",
      "|     Debt collection|(50,[3,6,8,14,23,...|  1.0|\n",
      "|Credit reporting ...|(50,[1,2,3,10,17,...|  0.0|\n",
      "|            Mortgage|(50,[4,5,6,10,13,...|  2.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8.0: 0.8, 0.0: 0.8, 7.0: 0.8, 1.0: 0.8, 4.0: 0.8, 11.0: 0.8, 14.0: 0.8, 3.0: 0.8, 2.0: 0.8, 17.0: 0.8, 10.0: 0.8, 13.0: 0.8, 6.0: 0.8, 5.0: 0.8, 15.0: 0.8, 9.0: 0.8, 16.0: 0.8, 12.0: 0.8}\n",
      "+--------------------+--------------------+-----+\n",
      "|             label_f|            features|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|            Mortgage|(50,[4,5,9,10,11,...|  2.0|\n",
      "|            Mortgage|(50,[5,10,14,16,1...|  2.0|\n",
      "|Credit reporting ...|(50,[1,2,3,10,17,...|  0.0|\n",
      "|            Mortgage|(50,[4,5,6,10,13,...|  2.0|\n",
      "|Credit reporting ...|(50,[0,2,6,24,31,...|  0.0|\n",
      "|     Debt collection|(50,[13,33,49],[1...|  1.0|\n",
      "|Credit reporting ...|(50,[0,1,2,16,29,...|  0.0|\n",
      "|Credit reporting ...|(50,[0,2,7,11,15,...|  0.0|\n",
      "|Checking or savin...|(50,[1,2,3,5,8,9,...|  6.0|\n",
      "|            Mortgage|(50,[1,4,5,6,11,1...|  2.0|\n",
      "|     Debt collection|(50,[0,1,4,6,7,10...|  1.0|\n",
      "|Credit reporting ...|(50,[4,7,14,17,18...|  0.0|\n",
      "|Credit reporting ...|(50,[0,1,2,5,9,13...|  0.0|\n",
      "|Credit card or pr...|(50,[5,9,11,12,13...|  3.0|\n",
      "|     Debt collection|(50,[0,1,2,3,10,1...|  1.0|\n",
      "|Credit card or pr...|(50,[0,1,2,3,8,11...|  3.0|\n",
      "|     Debt collection|(50,[0,2,10,15,26...|  1.0|\n",
      "|Credit card or pr...|(50,[1,7,10,11,12...|  3.0|\n",
      "|Credit card or pr...|(50,[0,1,3,5,9,11...|  3.0|\n",
      "|Credit reporting ...|(50,[0,1,2,3,5,7,...|  0.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed= 10\n",
    "\n",
    "#https://sparkbyexamples.com/spark/using-lit-and-typedlit-to-add-a-literal-or-constant-to-spark-dataframe/\n",
    "fractions = cc_df.select(\"label\").distinct().withColumn(\"fraction\", lit(0.8)).rdd.collectAsMap()\n",
    "print(fractions)  \n",
    "\n",
    "#https://spark.apache.org/docs/latest/api/R/sampleBy.html\n",
    "sampled_df = cc_df.stat.sampleBy(\"label\", fractions, seed)\n",
    "sampled_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__cache trainset and check time difference in training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "cc_df = cc_df.dropDuplicates()\n",
    "\n",
    "train = cc_df.sampleBy(\"label\", fractions=fractions, seed=seed).cache() # to compute times\n",
    "\n",
    "# Subtracting 'train' from original 'data' to get test set \n",
    "#subtract(other, numPartitions=None)[source]\n",
    "#Return each value in self that is not contained in other\n",
    "\n",
    "#works when duplicates removed\n",
    "test = cc_df.subtract(train)\n",
    "\n",
    "##Using ExceptAll because of having duplicates, since the lexicon is small its not rare to have same features and labels\n",
    "#test = cc_df.exceptAll(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304095\n",
      "76078\n"
     ]
    }
   ],
   "source": [
    "print(train.count()) # train rows\n",
    "print(test.count()) # test rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380173\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  8.0|13957|\n",
      "|  0.0|73716|\n",
      "|  7.0|17756|\n",
      "|  1.0|86644|\n",
      "|  4.0|22945|\n",
      "| 11.0| 7370|\n",
      "| 14.0| 1442|\n",
      "|  3.0|29723|\n",
      "|  2.0|58387|\n",
      "| 17.0|   14|\n",
      "| 10.0| 7831|\n",
      "| 13.0| 1675|\n",
      "|  6.0|17935|\n",
      "|  5.0|23861|\n",
      "| 15.0| 1396|\n",
      "|  9.0| 9054|\n",
      "| 16.0|  284|\n",
      "| 12.0| 6183|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cc_df.count())\n",
    "cc_df.groupby(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  8.0|11155|\n",
      "|  0.0|59109|\n",
      "|  7.0|14219|\n",
      "|  1.0|69065|\n",
      "|  4.0|18358|\n",
      "| 11.0| 5924|\n",
      "| 14.0| 1143|\n",
      "|  3.0|23787|\n",
      "|  2.0|46694|\n",
      "| 17.0|   13|\n",
      "| 10.0| 6279|\n",
      "| 13.0| 1347|\n",
      "|  6.0|14377|\n",
      "|  5.0|19062|\n",
      "| 15.0| 1112|\n",
      "|  9.0| 7274|\n",
      "| 16.0|  232|\n",
      "| 12.0| 4945|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###show rows for each label for train \n",
    "train.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  8.0| 2802|\n",
      "|  0.0|14607|\n",
      "|  7.0| 3537|\n",
      "|  1.0|17579|\n",
      "|  4.0| 4587|\n",
      "| 11.0| 1446|\n",
      "| 14.0|  299|\n",
      "|  3.0| 5936|\n",
      "|  2.0|11693|\n",
      "| 17.0|    1|\n",
      "| 10.0| 1552|\n",
      "| 13.0|  328|\n",
      "|  6.0| 3558|\n",
      "| 15.0|  284|\n",
      "|  5.0| 4799|\n",
      "|  9.0| 1780|\n",
      "| 16.0|   52|\n",
      "| 12.0| 1238|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###show rows for each label for test \n",
    "test.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|             label_f|            features|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|Bank account or s...|(50,[1,8,11,19,49...|  8.0|\n",
      "|     Debt collection|(50,[30,31,34,46,...|  1.0|\n",
      "|Credit card or pr...|(50,[0,8,9,11,15,...|  3.0|\n",
      "|Credit reporting ...|(50,[0,3,9,11,13,...|  0.0|\n",
      "|            Mortgage|(50,[4,5,6,9,10,1...|  2.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|             label_f|            features|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|Bank account or s...|(50,[0,1,3,4,5,8,...|  8.0|\n",
      "|Bank account or s...|(50,[0,1,3,5,8,9,...|  8.0|\n",
      "|Bank account or s...|(50,[0,1,5,8,11,1...|  8.0|\n",
      "|Bank account or s...|(50,[0,1,5,8,21,2...|  8.0|\n",
      "|Bank account or s...|(50,[1,2,5,8,11,1...|  8.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__code fraction another way__\n",
    "\n",
    "\n",
    "classes = cc_df.groupBy(\"label\").count().count()\n",
    "\n",
    "dicts = {}\n",
    "\n",
    "keys = range(classes)\n",
    "\n",
    "for i in keys:\n",
    "\n",
    "        dicts[i] = 0.8\n",
    "        \n",
    "train = dataDF.sampleBy(\"label\", fractions = dicts)\n",
    "\n",
    "train = train.cache()\n",
    "\n",
    "test = dataDF.subtract(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.5611346249901417\n"
     ]
    }
   ],
   "source": [
    "# specify layers for the neural network:\n",
    "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "layers = [lexicon_size,40,30,20,18]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "model = trainer.fit(train)\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
